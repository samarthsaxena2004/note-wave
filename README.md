# ğŸŒŠ NoteWave

**NoteWave** is an AI-powered application inspired by Google's NotebookLM. It transforms static PDF documents into interactive conversations and engaging audio podcasts.

Built as a showcase of bleeding-edge **Full-Stack AI Engineering**, utilizing **Next.js 16**, Vector Search, and Multi-Modal LLMs.

## âš ï¸ Important Notice

**It is strongly recommended to run this application locally.**

The publicly deployed version is intended as a portfolio demo. Because it relies on free-tier API keys (Groq & ElevenLabs), it may be **rate-limited**, become unavailable, or run out of credits without notice.

Running it locally gives you full control, unlimited usage (subject to your own keys), and guarantees data privacy.

---

## ğŸš€ What It Does

* **ğŸ“„ RAG-Powered Chat:** Upload any PDF and chat with it. The AI cites its sources by finding the exact paragraph in the document using Vector Search (Pinecone).
* **ğŸ™ï¸ AI Podcast Studio:** Generates a scripted "Deep Dive" audio conversation between two AI hosts (Host & Expert) who discuss the uploaded content.
* **âš¡ Real-Time Streaming:** Uses React Server Components to stream AI responses token-by-token for a zero-latency feel.
* **ğŸ¨ Teleprompter UI:** A custom-built audio player that auto-scrolls through the script as the AI speaks (Karaoke style).

## ğŸ“¸ Interface Preview

### 1. The Dashboard (Active State)
Once a document is uploaded, the interface transforms into a fully-featured research studio with Chat, Source Management, and the Audio Studio.

![NoteWave Dashboard](https://github.com/samarthsaxena2004/note-wave/blob/main/public/active-state.png)

### 2. The Landing Page (Zero State)
A clean, welcoming drop-zone for new users to get started immediately.

![NoteWave Landing](https://github.com/samarthsaxena2004/note-wave/blob/main/public/zero-state.png)

---

## ğŸ› ï¸ Tech Stack (The "Under the Hood")

* **Frontend:** [Next.js 16 (Turbopack)](https://nextjs.org/) - *Using the latest React 19 features.*
* **Language:** TypeScript
* **Styling:** Tailwind CSS, Shadcn/UI, Lucide React.
* **AI Logic:** Llama 3.3 70B (via Groq) for high-speed reasoning.
* **Vector DB:** Pinecone (Serverless) for semantic retrieval.
* **Embeddings:** Hugging Face (`all-MiniLM-L6-v2`) for vectorization.
* **Audio Engine:** ElevenLabs API for neural speech synthesis.
* **State Management:** Complex React Hooks (`useRef`, `useEffect`) to handle async audio loops.

## ğŸ§  System Architecture

1.Â  **Ingestion Pipeline:**
Â  Â  * PDF is parsed -> Text is split into semantic chunks (1000 chars) -> Chunks are vectorized -> Vectors stored in Pinecone with metadata.
2.Â  **Context-Aware Chat:**
Â  Â  * User query is embedded -> Pinecone finds top 10 relevant matches -> Llama 3 generates answer based *only* on those matches (reducing hallucinations).
3.Â  **Podcast Generation:**
Â  Â  * Llama 3 writes a JSON-structured script -> Frontend iterates through the script -> Calls ElevenLabs for audio -> Plays chunks sequentially.

## ğŸ§ª Challenges & Learnings

Building this required solving several complex engineering problems:

* **API Rate Limiting:** Implemented a "Batching & Backoff" system to upload vectors to Hugging Face without hitting 429 errors.
* **Context Isolation:** Built a filtering system so the AI only searches the *active* document, preventing data leaks between files.
* **State Synchronization:** Created a robust audio controller using `useRef` to manage the pause/resume state of an asynchronous fetch loop.

---

## ğŸš€ How to Run Locally

1.Â  **Clone the repo:**
Â  Â  ```bash
Â  Â  git clone [https://github.com/yourusername/notewave.git](https://github.com/yourusername/notewave.git)
Â  Â  cd notewave
Â  Â  ```
2.Â  **Install dependencies:**
Â  Â  ```bash
Â  Â  npm install
Â  Â  ```
3.Â  **Set Up Environment Variables:**
Â  Â  Create a `.env.local` file in the root directory and add your API keys:
Â  Â  ```env
Â  Â  GROQ_API_KEY=gsk_...
Â  Â  PINECONE_API_KEY=pcsk_...
Â  Â  PINECONE_INDEX_NAME=note-wave
Â  Â  HUGGINGFACE_API_KEY=hf_...
Â  Â  ELEVENLABS_API_KEY=sk_...
Â  Â  ```
4.Â  **Run the Development Server:**
Â  Â  ```bash
Â  Â  npm run dev
Â  Â  ```
Â  Â  Open [http://localhost:3000](http://localhost:3000) in your browser.

> **Troubleshooting:** If the application fails due to a retired model or deprecated API call, please refer to the comprehensive debugging steps in the [`MAINTENANCE_GUIDE.md`](MAINTENANCE_GUIDE.md) file in the repository root.

---

## ğŸ¤ Contributing

Contributions are welcome! If you have ideas for features (e.g., persistent database storage, user authentication), feel free to fork the repo and submit a PR.

1.Â  Fork the Project
2.Â  Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3.Â  Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4.Â  Push to the Branch (`git push origin feature/AmazingFeature`)
5.Â  Open a Pull Request

---

### Crafted with â¤ï¸ by [Samarth Saxena](https://enflect.tech/)
